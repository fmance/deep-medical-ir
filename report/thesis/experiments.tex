\chapter{Experiments}

In this chapter, we present the application of the theory from the previous section. Concretely, we apply the system on Trec 2014 and 2015
clinical decision support track. 
The CDS track consists of medical question, describing symptoms and other relevant information. The question is to diagnose/test/treat
the patient.
The input consists of 30 queries from 2014 and 2015 each. Each query contains description and summary. Also type.
We have approximately 733K documents to search from.

Example query:

We also have ground truths, i.e. labels for around x percent of the query-doc pairs, based on trec 14,15. 

We first one to apply the baseline IR system on the queries, then use the classifier and fusion as described in the prev. section.
This is applied for both 2014, 2015.

\section{Implementation}

\subsection{Computing the similarity scores}
As mentioned in the methodology section, we use BM25 to compute the similarity scores between queries and documents.
We use the Lucene information retrieval system for indexing and searching.

Indexing happens in two stages:
\begin{enumerate}
 \item parsing the NXML file format into plain-text (article title, abstract and body), using Java's DOM parser;
 \item indexing the parsed text, using the \texttt{BM25Similarity} and the \texttt{EnglishAnalyzer} for tokenizing and stemming the text.
\end{enumerate}

At query time, we parse the queries' XML file and retrieve the top 100 results per query, using the same configuration as for indexing.
For each year, 2014 and 2015, we produce two results file: one using the query summaries and another one using the query descriptions.


\subsection{Computing the classifier scores}


\subsection{Fusing the similarity and classifier scores}
Now that we have both the similarity scores and classifier scores, we can finally fuse them together. 
For the unsupervised fusion methods (linear interpolation, RRF and Borda Fuse), we min-max-normalize both the BM25 scores
and the classification scores for each query, and fuse the scores as described in the methodology section. The $\lambda$-weight
is varied in the $[0,1]$ interval, in steps of $0.01$.


\section{Evaluation Metric}
We use precision at 10 (P@10) as the evauation metric. P@10 counts how many relevant results we have in the top 10 retrieved results, for each query.
The relevance judjements for each query are stored in a \emph{qrels} file, with each document in this file receiving a score of 0, 1 or 2, depending on whether it
is not relevant, possibly relevant or definitely relevant, respectively. The relevance judgements were assigned by medical experts after each edition of TREC.

For measuring the P@10, we count both 1 and 2 as relevant. Note that only a
fraction of the 730K documents are actually judged (and in the qrels files), so it may happen that some documents retrieved by our system
are mis-counted as being not relevant simply because they have not been judged.


\section{Results}
\subsection{Classifier Parameters}
Table \ref{params} lists the classifiers we use and their configurations (loss function, penalty). We empirically determine
the regularization
parameters by varying them in a cerain range (for example, $[10^{-4},\cdots,10^4]$ in steps of powers of 10) and choosing the ones
that give the
best P@10 improvement averaged over all four categories.
For the Multilayer-perceptron we use two layers of size 50 and 5 respectively. For the Neural Networks,
we use 100 convolution filters of size 3, 4 and 5, respectively and 50 nodes in next hidden layer. The word-embedding size is 100 
and is computed using \texttt{word2vec} over the preprocessed TREC 2014 document corpus.


% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{graphicx}
\begin{table}[]
\centering
\caption{Best classifier parameters found}
\label{params}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llllll@{}}
\toprule
\textbf{Classifier}             & \textbf{Loss function}  & \textbf{Penalty} & \textbf{Regularization parameter}                             &  &  \\ \midrule
SVM               		& Precision@K		 & L2               & $10^{-3}$                                                 &  &  \\
SVM               		& Recall @K		 & L2               & $10^{-3}$                                               &  &  \\
SVM           			& ROC area		 & L2               & $10^{-3}$                                                &  &  \\
SVM           			& Error-rate		& L2               & $1$                                                     &  &  \\
SVM                 		& F1			& L2               & $1$                                                     &  &  \\
SVM           			& Zero/one		& L2               & $10^{-2}$                                                  &  &  \\
SVM      			& $\epsilon$-insensitive	& Elasticnet       & $10^{-2}$                                              &  &  \\
SVM              		& Hinge 		& L2               & $10^{-3}$                                                 &  &  \\
SVM       			& Squared hinge		& L2               & $10^{-3}$                                                 &  &  \\
SVM             		& Squared		& Elasticnet       & $10^{-2}$                                              &  &  \\
Ridge               		& Squared		 & L2               & $10^{-4}$                                             &  &  \\
Logistic Regression             & Log			& L2               & $10^{-1}$                                                   &  &  \\
Passive Aggressive		& Hinge 		&             & $10^{-2}$                                                  &  &  \\
Perceptron                      &			& Elasticnet             & $10^{-4}$                                            &  &  \\
Multilayer Perceptron          & Log			& Elasticnet       & $10^{-6}$                                                        &  &  \\
Neural Networks                 & Cross-entropy		& L2               & $10^{-4}$ &  &  \\ 
Naive Bayes                    	& 			 &              & $10^{-3}$ (Laplace smoothing)                            &  &  \\\bottomrule
\end{tabular}%
}
\end{table}

\subsection{Unsupervised Reranking}

\subsubsection{Linear Combination}
Table \ref{interpolation-res} lists the absolute P@10 improvements of the reranked results, using the linear combination of BM25 and classifier scores (formula \ref{interp-formula}),
with the best $\lambda$ being $0.7\pm 0.02$.

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{graphicx}
\begin{table}[h!]
\centering
\caption{Absolute P@10 improvement over the baseline, using weighted \textbf{linear combination fusion} of the baseline BM25 scores and the classifier scores.}
\label{interpolation-res}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llllll@{}}
\toprule
  & \textbf{Summaries 2014} & \textbf{Descriptions 2014} & \textbf{Summaries 2015} & \textbf{Descriptions 2015} & \textbf{Average} \\ 
Baseline                             & 31.67                   & 25                         & 38.67                   & 35                         &   32.59               \\ \midrule
SVM (with Precision@K loss)                                 & +8                       & +9                          & +\textbf{4}              & +3.33                       & +\textbf{6.08}    \\ 
SVM (with Rec@K loss)                                    & +\textbf{8.33}           & +\textbf{10}                & +3                       & +2.67                       & +6                \\ 
Ridge                                          & +7                       & +9                          & +3.33                    & +\textbf{4}                 & +5.83             \\ 
SVM (with ROC area loss)                                    & +7.67                    & +9.67                       & +2                       & +3.67                       & +5.75             \\ 
SVM (with Error-rate loss)                                 & +8                       & +8.67                       & +3                       & +3                          & +5.67             \\ 
SVM (with Squared hinge loss)                           & +7                       & +9                          & +3                       & +3.67                       & +5.67             \\ 
Logistic Regression                            & +7.67                    & +8.67                       & +3                       & +3                          & +5.59             \\ 
SVM (with Squared loss)                               & +7.67                    & +9.33                       & +3.33                    & +1.67                       & +5.5              \\ 
SVM (with F1 loss)                                       & +7                       & +8.67                       & +2.67                    & +3.33                       & +5.42             \\ 
SVM (with Zero/one loss)                                        & +7                       & +8.67                       & +3                       & +3                          & +5.42             \\ 
Passive Aggressive                             & +6                       & +8                          & +2.33                    & +4                          & +5.08             \\ 
SVM (with $\epsilon$-insensitive loss)                            & +6.33                    & +7.67                       & +2.67                    & +3                          & +4.92             \\ 
SVM (with Hinge loss)                                     & +5.33                    & +8                          & +2                       & +3.67                       & +4.75             \\ 
Multilayer Perceptron                           & +7.67                    & +8                          & +1.67                    & +1                          & +4.59             \\ 
Neural Networks                               & +3                       & +5.67                       & +2.33                    & 0                          & +2.75             \\ 
Perceptron                                      & +4.33                    & +4.33                       & +0.33                    & 0                          & +2.25             \\ 
Naive Bayes                                      & +3                       & +4                          & +1                       & -1                         & +1.75             \\ \bottomrule
\end{tabular}%
}
\end{table}

The best rerankers are the ones using SVM classifiers, with the top one giving an overall improvement of over 6 percentage
points in P@10. For 2014, the best classifier was SVM with Rec@K loss (8.33\% and 10\% improvements), 
and for 2015 they were SVM with Precision@K loss and Ridge (4\% improvements).

In particular, for summaries 2014, the top reranked result is $31.67\%+8.33\% = 40\%$, which is better than the top automatic submission
from TREC 2014 (39\%).

Generally, the improvements for 2014 are at least 
twice as high as the ones for 2015, but this may be due to the lower baseline precisions from 2014 compared to 2015.

Looking more closely, we can see that all the top 10 classifiers are not more than 0.7\% worse off compared to the top one. However, the bottom three
are clearly worse, yielding improvements less than 3\%. In the case of neural networks, the problem might be the small size of the training data,
while the Perceptron and Bayes classifiers are too naive for this kind of task.


\begin{figure}
\centerline{
  \includegraphics[scale=0.22]{../../ranking/plots/interpolation/all/all.SVMPerf.04.0.001.hedges.png}
  }
  \caption{P@10 improvements using linear combination and SVM with Precision@K loss function.}
\end{figure}


\begin{figure}
\centerline{
  \includegraphics[scale=0.22]{../../ranking/plots/interpolation/all/all.SVMPerf.05.0.001.hedges.png}
  }
  \caption{P@10 improvements using linear combination and SVM with Recall@K loss function.}
\end{figure}

\begin{figure}
\centerline{
  \includegraphics[scale=0.27]{../../ranking/plots/bar/all.SVMPerf.04.0.001.hedges.interpolation.png}
  }
  \caption{P@10 improvements per query using linear combination and SVM with Recall@K loss function.}
\end{figure}




\subsubsection{Reciprocal Rank Fusion}
Table \ref{rrf-res} lists the absolute P@10 improvements of the reranked results, using Reciprocal Rank Fusion of the BM25 and classifier ranks (formula \ref{rrf-formula}),
with the best $\lambda$ being $0.6\pm 0.02$.
Similar to the linear combination method, SVM gave the best results, although the best one here uses a squared loss instead of 
Precision@K (which came out fourth).

However, the RRF improvements are overall lower than for linear combination: the best improvement is 4.75\% compared to 6\%, respectively. One reason
might be that RRF loses some information by not using the actual scores, but just the ranks instead.

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{graphicx}
\begin{table}[h!]
\centering
\caption{Absolute P@10 improvement over the baseline, using weighted \textbf{reciprocal rank fusion} of the baseline BM25 scores and the classifier scores.}
\label{rrf-res}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llllll@{}}
\toprule
                                    & \textbf{Summaries 2014} & \textbf{Descriptions 2014} & \textbf{Summaries 2015} & \textbf{Descriptions 2015} & \textbf{Average} \\ 
Baseline                                   & 31.67                   & 25                         & 38.67                   & 35                         &   32.59               \\ \midrule

SVM (with Squared loss)                               & +5                       & +7.33                       & +3.67                    & +\textbf{3}                          & +\textbf{4.75}             \\ 
SVM (with Rec@K loss)                                                                      & +5                       & +\textbf{7.67}                       & +{3}              & +2                          & +{4.42}    \\ 
Passive Aggressive                                       & +\textbf{5.33}           & +5.67              & +2.33                    & +2.67                       & +4                \\ 
SVM (with Precision@K loss)                                                                 & +3.67                    & +7                          & +3.33                    & +{1.67}              & +3.92             \\ 
SVM (with F1 loss)                                                                          & +4.33                    & +6.33                       & +2.67                    & +2.33                       & +3.92             \\ 
Logistic Regression                                                      & 3.67                    & +7                          & +2.67                    & +2                          & +3.84             \\ 
SVM (with Hinge loss)                                                                        & +4                       & +5.67                       & +2.67                    & +\textbf{3}                          & +3.84             \\ 
SVM (with Error-rate loss)                                                                    & +4.33                    & +6                          & +3.33                    & +1.67                       & +3.83             \\ 
SVM (with Squared hinge loss)                                                              & +3.67                    & +6.33                       & +2.33                    & +2.67                       & +3.75             \\ 
Ridge                                                             & +3.33                    & +7                          & +2.33                    & +2                          & +3.67             \\ 
SVM (with $\epsilon$-insensitive loss)                         & +4.33                    & +6.67                       & +1.67                    & +1.67                       & +3.59             \\ 
SVM (with ROC area loss)                                                                    & +3.33                    & +7                          & +2.33                    & +1.67                       & +3.58             \\ 
SVM (with Zero/one loss)                                                                        & +4                       & +5.67                       & +2.33                    & +2.33                       & +3.58             \\ 
Multilayer Perceptron								& +4 & +6.33 & +2 & +0 & +3.08 \\
Naive Bayes                                                                      & +5                       & +5.67                       & +1.33                    & -1                         & +2.75             \\ 
Neural Networks                                                                   & +3.67                    & +4.67                       & 0                       & +1                          & +2.34             \\ 
Perceptron                                                              & +2                       & +3                          & +1                       & 0                          & +1.5              \\ \bottomrule
\end{tabular}%
}
\end{table}

\begin{figure}[h!]
\centerline{
  \includegraphics[scale=0.22]{../../ranking/plots/rrf/all/all.SGDClassifier.squared_loss.elasticnet.hedges.png}
  }
  \caption{P@10 improvements using RRF and SVM with squared loss function.}
\end{figure}

\begin{figure}
\centerline{
  \includegraphics[scale=0.27]{../../ranking/plots/bar/all.SGDClassifier.squared_loss.elasticnet.hedges.rrf.png}
  }
  \caption{P@10 improvements per query using RRF and SVM with squared loss function.}
\end{figure}



\subsubsection{Borda Fuse}
Weight was $0.6\pm0.05$

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{graphicx}
\begin{table}[h!]
\centering
\caption{Absolute P@10 improvement over the baseline, using weighted \textbf{Borda fusion} of the baseline BM25 scores and the classifier scores.}
\label{borda-res}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllllll@{}}
\toprule
                                       & Summaries 2014 & Descriptions 2014 & Summaries 2015 & Descriptions 2015 & Average       \\
Baseline                                   & 31.67                   & 25                         & 38.67                   & 35                         &   32.59               \\ \midrule
                                   
SVM (with Squared loss)                               & +\textbf{4.67}  & +\textbf{8.67}     & +2.33           & +\textbf{1.33}     & +\textbf{4.25} \\
SVM (with Precision@K loss)                            & +4              & +9                 & +1.67           & +\textbf{1.33}     & +4             \\
SVM (with Rec@K loss)                                 & +4.33           & +7.67              & +3.33           & +0.67              & +4             \\
Logistic Regression                                    & +4.33           & +8                 & +2              & +\textbf{1.33}     & +3.92          \\
SVM (with Error-rate loss)                             & +4.33           & +6                 & +3.33           & +1                 & +3.67          \\
SVM (with F1 loss)                                     & +4              & +5.67              & +4              & +1                 & +3.67          \\
SVM (with Squared hinge loss)                           & +3              & +8                 & +2              & +\textbf{1.33}     & +3.58          \\
SVM (with Zero/one loss)                               & +3.67           & +5.67              & +\textbf{3.67}  & +1                 & +3.5           \\
Ridge                                                   & +3              & +8                 & +1.33           & +1                 & +3.33          \\
SVM (with ROC area loss)                                & +3.67           & +8                 & +1.33           & +0.33              & +3.33          \\
SVM (with $\epsilon$-insensitive loss)                   & +3.33           & +7                 & +1.33           & +1                 & +3.17          \\
Passive Aggressive                                       & +3.67           & +5                 & +1.67           & +1                 & +2.84          \\
SVM (with Hinge loss)                                    & +2              & +6.33              & +0.67           & +1                 & +2.5           \\
Multilayer Perceptron                                 & +2.67           & +6.33              & +1              & +-1                & +2.25          \\
Naive Bayes                                              & +3.33           & +6.33              & +0.33           & +-3                & +1.75          \\
Neural Networks                                         & +1              & +4.33              & +-1             & +-1                & +0.83          \\
Perceptron                                              & +1.33           & +2                 & +0.67           & +-2.33             & +0.42         \\\bottomrule
\end{tabular}%
}
\end{table}

\begin{figure}
\centerline{
  \includegraphics[scale=0.22]{../../ranking/plots/borda/all/all.SGDClassifier.squared_loss.elasticnet.hedges.png}
  }
  \caption{P@10 improvements using Borda fusion and SVM with squared loss function.}
\end{figure}



\begin{figure}
\centerline{
  \includegraphics[scale=0.27]{../../ranking/plots/bar/all.SGDClassifier.squared_loss.elasticnet.hedges.borda.png}
  }
  \caption{P@10 improvements per query using Borda fusion and SVM with Squared loss function.}
\end{figure}






